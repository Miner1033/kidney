{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline:\n",
        "  1.  Load & Explore Datasets\n",
        "  2.  Harmonize & Merge\n",
        "  3.  Preprocessing (Imputation + Encoding)\n",
        "  4.  Stratified Train/Test Split (80/20)\n",
        "  5.  SMOTE Oversampling (Training only)\n",
        "  6.  Feature Scaling\n",
        "  7.  Ensemble Feature Selection (Chi2 + MI + RFE)  [train-only]\n",
        "  8.  10-Fold Stratified Cross-Validation\n",
        "  9.  Test Set Evaluation (7 Classifiers)\n",
        "  10. Soft Voting Ensemble (RF + HistGB + GB)\n",
        "  11. Confusion Matrices\n",
        "  12. Model Comparison Plot\n",
        "  13. SHAP Explainability\n",
        "  14. Save all results\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7wqQQrsI2QPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1. IMPORTS\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import (train_test_split, StratifiedKFold,\n",
        "                                     cross_validate)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_selection import (chi2, mutual_info_classif,\n",
        "                                       SelectKBest, RFE)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (RandomForestClassifier,\n",
        "                               GradientBoostingClassifier,\n",
        "                               HistGradientBoostingClassifier,\n",
        "                               VotingClassifier)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import (accuracy_score, f1_score, roc_auc_score,\n",
        "                              classification_report, confusion_matrix,\n",
        "                              ConfusionMatrixDisplay)\n",
        "from statsmodels.stats.proportion import proportion_confint\n",
        "import shap\n",
        "\n",
        "print(\"=\" * 65)\n",
        "print(\"  CHRONIC KIDNEY DISEASE â€” ML PIPELINE\")\n",
        "print(\"=\" * 65)\n",
        "print(\"âœ… All libraries imported\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT1X7CSG2Rn5",
        "outputId": "718cd5bc-cc74-4db0-c974-06b8430e2209"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "  CHRONIC KIDNEY DISEASE â€” ML PIPELINE\n",
            "=================================================================\n",
            "âœ… All libraries imported\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2. LOAD DATASETS\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"STEP 1: LOADING DATASETS\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "df1 = pd.read_csv(\"chronic_kidney_disease.csv\")\n",
        "df1.columns = df1.columns.str.strip()\n",
        "df1.replace('?', np.nan, inplace=True)\n",
        "print(f\"Dataset 1 (UCI CKD)      shape: {df1.shape}\")\n",
        "\n",
        "df2 = pd.read_csv(\"Chronic_Kidney_Dsease_data.csv\")\n",
        "print(f\"Dataset 2 (Extended CKD) shape: {df2.shape}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7Qks_Xw2VpQ",
        "outputId": "0e3f4927-39e3-4d01-877b-962b87e8eca6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: LOADING DATASETS\n",
            "---------------------------------------------\n",
            "Dataset 1 (UCI CKD)      shape: (400, 25)\n",
            "Dataset 2 (Extended CKD) shape: (1659, 54)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3. HARMONIZE & MERGE\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"STEP 2: HARMONIZE & MERGE\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "# â”€â”€ UCI Dataset â”€â”€\n",
        "d1 = df1.copy()\n",
        "d1['class'] = d1['class'].str.strip().str.replace('\\t', '')\n",
        "d1['target'] = d1['class'].map({'ckd': 1, 'notckd': 0})\n",
        "d1.drop(columns=['class'], inplace=True)\n",
        "\n",
        "uci_num = ['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc',\n",
        "           'sod', 'pot', 'hemo', 'pcv', 'wbcc', 'rbcc']\n",
        "uci_cat = ['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n",
        "\n",
        "le = LabelEncoder()\n",
        "for col in uci_cat:\n",
        "    if col in d1.columns:\n",
        "        mask = d1[col].notna() & (d1[col].astype(str) != 'nan')\n",
        "        vals = d1.loc[mask, col].astype(str)\n",
        "        if len(vals) > 0:\n",
        "            le.fit(vals)\n",
        "            d1.loc[mask, col] = le.transform(vals)\n",
        "            d1.loc[~mask, col] = np.nan\n",
        "\n",
        "for col in uci_num:\n",
        "    if col in d1.columns:\n",
        "        d1[col] = pd.to_numeric(d1[col], errors='coerce')\n",
        "\n",
        "d1_fin = d1[uci_num + uci_cat + ['target']].copy()\n",
        "d1_fin['_src'] = 'uci'\n",
        "\n",
        "# â”€â”€ Extended Dataset â”€â”€\n",
        "d2 = df2.copy()\n",
        "d2_sel = pd.DataFrame()\n",
        "d2_sel['age']    = d2['Age']\n",
        "d2_sel['bp']     = d2['SystolicBP']\n",
        "d2_sel['sc']     = d2['SerumCreatinine']\n",
        "d2_sel['bu']     = d2['BUNLevels']\n",
        "d2_sel['hemo']   = d2['HemoglobinLevels']\n",
        "d2_sel['sod']    = d2['SerumElectrolytesSodium']\n",
        "d2_sel['pot']    = d2['SerumElectrolytesPotassium']\n",
        "d2_sel['bgr']    = d2['FastingBloodSugar']\n",
        "d2_sel['htn']    = d2['FamilyHistoryHypertension'].astype(float)\n",
        "d2_sel['dm']     = d2['FamilyHistoryDiabetes'].astype(float)\n",
        "d2_sel['target'] = d2['Diagnosis'].astype(int)\n",
        "d2_sel['_src']   = 'ext'\n",
        "\n",
        "for col in d1_fin.columns:\n",
        "    if col not in d2_sel.columns:\n",
        "        d2_sel[col] = np.nan\n",
        "\n",
        "# â”€â”€ Merge â”€â”€\n",
        "merged = pd.concat([d1_fin, d2_sel], ignore_index=True, sort=False)\n",
        "merged.drop(columns=['_src'], inplace=True)\n",
        "merged.to_csv(\"merged_ckd_dataset.csv\", index=False)\n",
        "\n",
        "print(f\"âœ… Merged shape : {merged.shape}\")\n",
        "print(f\"   CKD     (1) : {(merged['target']==1).sum()}\")\n",
        "print(f\"   Not CKD (0) : {(merged['target']==0).sum()}\")\n",
        "print(\"ğŸ’¾ Saved : merged_ckd_dataset.csv\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDw3TE8P2a2l",
        "outputId": "3fe471bc-141c-45a6-98b0-e32f9a4fed89"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 2: HARMONIZE & MERGE\n",
            "---------------------------------------------\n",
            "âœ… Merged shape : (2059, 25)\n",
            "   CKD     (1) : 1774\n",
            "   Not CKD (0) : 284\n",
            "ğŸ’¾ Saved : merged_ckd_dataset.csv\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4. PREPROCESSING\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"STEP 3: PREPROCESSING\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "X = merged.drop(columns=['target'])\n",
        "\n",
        "# target-à¦ NaN à¦¥à¦¾à¦•à¦²à§‡ à¦¸à§‡à¦‡ rows drop à¦•à¦°à§‹\n",
        "merged_clean = merged.dropna(subset=['target'])\n",
        "X = merged_clean.drop(columns=['target'])\n",
        "y = merged_clean['target'].astype(int)\n",
        "print(f\"Rows dropped (NaN target): {len(merged) - len(merged_clean)}\")\n",
        "\n",
        "imp = SimpleImputer(strategy='median')\n",
        "X_imp = pd.DataFrame(imp.fit_transform(X), columns=X.columns)\n",
        "print(f\"Features : {X_imp.shape[1]}  |  Records : {X_imp.shape[0]}\")\n",
        "print(f\"Missing after imputation : {X_imp.isnull().sum().sum()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o5ffOQB29fu",
        "outputId": "ec3b9188-ab0b-4114-84bc-5efe289bda59"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 3: PREPROCESSING\n",
            "---------------------------------------------\n",
            "Rows dropped (NaN target): 1\n",
            "Features : 24  |  Records : 2058\n",
            "Missing after imputation : 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 5. STRATIFIED TRAIN/TEST SPLIT 80/20\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"STEP 4: STRATIFIED TRAIN/TEST SPLIT (80/20)\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "    X_imp, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Train : {X_tr.shape[0]}  |  Test : {X_te.shape[0]}\")\n",
        "print(f\"Train class dist : {dict(y_tr.value_counts().sort_index())}\")\n",
        "print(f\"Test  class dist : {dict(y_te.value_counts().sort_index())}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU5_3Rej2_mW",
        "outputId": "7c24c5a6-12fc-4b0c-d319-1bbc0cac87d7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 4: STRATIFIED TRAIN/TEST SPLIT (80/20)\n",
            "---------------------------------------------\n",
            "Train : 1646  |  Test : 412\n",
            "Train class dist : {0: np.int64(227), 1: np.int64(1419)}\n",
            "Test  class dist : {0: np.int64(57), 1: np.int64(355)}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 6. SMOTE (Training only)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"STEP 5: SMOTE OVERSAMPLING\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "X_tr_res, y_tr_res = SMOTE(random_state=42).fit_resample(X_tr, y_tr)\n",
        "print(f\"After SMOTE â†’ {X_tr_res.shape[0]} samples\")\n",
        "print(f\"Class dist : {dict(pd.Series(y_tr_res).value_counts().sort_index())}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIxgiRi23CUC",
        "outputId": "fad81803-ce4c-4f80-cb73-043172953ff8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 5: SMOTE OVERSAMPLING\n",
            "---------------------------------------------\n",
            "After SMOTE â†’ 2838 samples\n",
            "Class dist : {0: np.int64(1419), 1: np.int64(1419)}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 7. FEATURE SCALING\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "sc = StandardScaler()\n",
        "X_tr_sc = pd.DataFrame(sc.fit_transform(X_tr_res), columns=X_tr_res.columns)\n",
        "X_te_sc  = pd.DataFrame(sc.transform(X_te),        columns=X_te.columns)\n"
      ],
      "metadata": {
        "id": "VQ0IU2QB3FPQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 8. ENSEMBLE FEATURE SELECTION\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"STEP 6: ENSEMBLE FEATURE SELECTION (Chi2 + MI + RFE)\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "feats = X_tr_sc.columns.tolist()\n",
        "k = min(11, len(feats))\n",
        "\n",
        "# Chi-Square\n",
        "chi2_sel = SelectKBest(chi2, k=k)\n",
        "chi2_sel.fit(X_tr_sc - X_tr_sc.min(), y_tr_res)\n",
        "chi2_f = set(np.array(feats)[chi2_sel.get_support()])\n",
        "\n",
        "# Mutual Information\n",
        "mi_sc = mutual_info_classif(X_tr_sc, y_tr_res, random_state=42)\n",
        "mi_f  = set(np.array(feats)[np.argsort(mi_sc)[::-1][:k]])\n",
        "\n",
        "# RFE\n",
        "rfe_sel = RFE(LogisticRegression(max_iter=1000, random_state=42),\n",
        "              n_features_to_select=k)\n",
        "rfe_sel.fit(X_tr_sc, y_tr_res)\n",
        "rfe_f = set(np.array(feats)[rfe_sel.support_])\n",
        "\n",
        "# Consensus â‰¥2\n",
        "votes   = {f: sum([f in chi2_f, f in mi_f, f in rfe_f]) for f in feats}\n",
        "consens = [f for f, v in votes.items() if v >= 2]\n",
        "\n",
        "print(f\"Chi-Square  ({len(chi2_f)}) : {sorted(chi2_f)}\")\n",
        "print(f\"Mutual Info ({len(mi_f)})  : {sorted(mi_f)}\")\n",
        "print(f\"RFE         ({len(rfe_f)}) : {sorted(rfe_f)}\")\n",
        "print(f\"\\nâœ… Consensus ({len(consens)}) : {sorted(consens)}\\n\")\n",
        "\n",
        "X_tr_sel = X_tr_sc[consens]\n",
        "X_te_sel  = X_te_sc[consens]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 5))\n",
        "vs = pd.Series(votes).sort_values(ascending=False)\n",
        "plt.bar(vs.index, vs.values,\n",
        "        color=['#2ecc71' if v >= 2 else '#e74c3c' for v in vs.values])\n",
        "plt.axhline(2, color='navy', ls='--', lw=1.5, label='Threshold â‰¥ 2')\n",
        "plt.title('Ensemble Feature Selection â€“ Votes per Feature', fontsize=14)\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Votes (out of 3)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_selection_votes.png', dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"ğŸ“Š Saved: feature_selection_votes.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "545Q3yAy3HfM",
        "outputId": "7944919b-b077-4068-fb13-c1292904301a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 6: ENSEMBLE FEATURE SELECTION (Chi2 + MI + RFE)\n",
            "---------------------------------------------\n",
            "Chi-Square  (11) : [np.str_('al'), np.str_('ane'), np.str_('appet'), np.str_('bp'), np.str_('cad'), np.str_('dm'), np.str_('htn'), np.str_('pcc'), np.str_('pe'), np.str_('sc'), np.str_('su')]\n",
            "Mutual Info (11)  : [np.str_('age'), np.str_('bgr'), np.str_('bp'), np.str_('dm'), np.str_('htn'), np.str_('pcv'), np.str_('rbcc'), np.str_('sc'), np.str_('sg'), np.str_('sod'), np.str_('wbcc')]\n",
            "RFE         (11) : [np.str_('al'), np.str_('appet'), np.str_('bgr'), np.str_('bp'), np.str_('bu'), np.str_('pcv'), np.str_('pe'), np.str_('rbcc'), np.str_('sc'), np.str_('sg'), np.str_('su')]\n",
            "\n",
            "âœ… Consensus (12) : ['al', 'appet', 'bgr', 'bp', 'dm', 'htn', 'pcv', 'pe', 'rbcc', 'sc', 'sg', 'su']\n",
            "\n",
            "ğŸ“Š Saved: feature_selection_votes.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 9. 10-FOLD STRATIFIED CROSS-VALIDATION\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"\\nSTEP 7: 10-FOLD STRATIFIED CROSS-VALIDATION\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "models = {\n",
        "    'Decision Tree':          DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest':          RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "    'Gradient Boosting':      GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "    'Hist Gradient Boosting': HistGradientBoostingClassifier(random_state=42),\n",
        "    'SVM':                    SVC(probability=True, random_state=42),\n",
        "    'KNN':                    KNeighborsClassifier(n_neighbors=5),\n",
        "    'Logistic Regression':    LogisticRegression(max_iter=1000, random_state=42),\n",
        "}\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "cv_res = {}\n",
        "\n",
        "for nm, clf in models.items():\n",
        "    cv = cross_validate(clf, X_tr_sel, y_tr_res, cv=skf,\n",
        "                        scoring=['accuracy', 'f1', 'roc_auc'])\n",
        "    cv_res[nm] = {\n",
        "        'CV Accuracy': round(cv['test_accuracy'].mean(), 4),\n",
        "        'CV F1':       round(cv['test_f1'].mean(), 4),\n",
        "        'CV AUC-ROC':  round(cv['test_roc_auc'].mean(), 4),\n",
        "    }\n",
        "    print(f\"  {nm:28s}| Acc:{cv_res[nm]['CV Accuracy']:.4f} \"\n",
        "          f\"| F1:{cv_res[nm]['CV F1']:.4f} \"\n",
        "          f\"| AUC:{cv_res[nm]['CV AUC-ROC']:.4f}\")\n",
        "\n",
        "cv_df = pd.DataFrame(cv_res).T\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0_9oa7c3Uk3",
        "outputId": "8a2a4a3a-a240-49d3-e4c8-7973e617ad6e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "STEP 7: 10-FOLD STRATIFIED CROSS-VALIDATION\n",
            "---------------------------------------------\n",
            "  Decision Tree               | Acc:0.8939 | F1:0.8930 | AUC:0.8939\n",
            "  Random Forest               | Acc:0.9263 | F1:0.9272 | AUC:0.9781\n",
            "  Gradient Boosting           | Acc:0.8989 | F1:0.9030 | AUC:0.9646\n",
            "  Hist Gradient Boosting      | Acc:0.9179 | F1:0.9185 | AUC:0.9742\n",
            "  SVM                         | Acc:0.8735 | F1:0.8823 | AUC:0.9450\n",
            "  KNN                         | Acc:0.8862 | F1:0.8852 | AUC:0.9591\n",
            "  Logistic Regression         | Acc:0.8111 | F1:0.8195 | AUC:0.9002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 10. TEST SET EVALUATION\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"\\nSTEP 8: TEST SET EVALUATION\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "te_res  = {}\n",
        "trained = {}\n",
        "\n",
        "for nm, clf in models.items():\n",
        "    clf.fit(X_tr_sel, y_tr_res)\n",
        "    trained[nm] = clf\n",
        "    yp   = clf.predict(X_te_sel)\n",
        "    yprb = clf.predict_proba(X_te_sel)[:, 1]\n",
        "\n",
        "    acc = accuracy_score(y_te, yp)\n",
        "    f1  = f1_score(y_te, yp)\n",
        "    auc = roc_auc_score(y_te, yprb)\n",
        "    te_res[nm] = {'Test Accuracy': acc, 'Test F1': f1, 'Test AUC-ROC': auc}\n",
        "    print(f\"  {nm:28s}| Acc:{acc:.4f} | F1:{f1:.4f} | AUC:{auc:.4f}\")\n",
        "\n",
        "te_df = pd.DataFrame(te_res).T\n",
        "\n",
        "best_nm = te_df['Test Accuracy'].idxmax()\n",
        "best_ac = te_df.loc[best_nm, 'Test Accuracy']\n",
        "nc      = int(round(best_ac * len(y_te)))\n",
        "ci_l, ci_h = proportion_confint(nc, len(y_te), method='wilson')\n",
        "print(f\"\\nâœ… Best: {best_nm} | Acc:{best_ac:.4f} | 95% CI:[{ci_l:.3f},{ci_h:.3f}]\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFQ3er8O3oFq",
        "outputId": "5fdb8c4a-3727-4fa2-89f8-703df8d7ed1b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "STEP 8: TEST SET EVALUATION\n",
            "---------------------------------------------\n",
            "  Decision Tree               | Acc:0.8762 | F1:0.9268 | AUC:0.7883\n",
            "  Random Forest               | Acc:0.8981 | F1:0.9412 | AUC:0.8708\n",
            "  Gradient Boosting           | Acc:0.9078 | F1:0.9472 | AUC:0.8759\n",
            "  Hist Gradient Boosting      | Acc:0.8859 | F1:0.9339 | AUC:0.8585\n",
            "  SVM                         | Acc:0.9126 | F1:0.9497 | AUC:0.8619\n",
            "  KNN                         | Acc:0.8519 | F1:0.9112 | AUC:0.8079\n",
            "  Logistic Regression         | Acc:0.8374 | F1:0.9007 | AUC:0.8782\n",
            "\n",
            "âœ… Best: SVM | Acc:0.9126 | 95% CI:[0.881,0.936]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 11. SOFT VOTING ENSEMBLE\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"STEP 9: SOFT VOTING ENSEMBLE (SVM + HistGB + GB)\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "# SVM probability=True à¦¦à¦¿à¦¤à§‡ à¦¹à¦¬à§‡ soft voting-à¦à¦° à¦œà¦¨à§à¦¯\n",
        "ens = VotingClassifier(estimators=[\n",
        "    ('SVM', SVC(probability=True, random_state=42)),\n",
        "    ('HGB', HistGradientBoostingClassifier(random_state=42)),\n",
        "    ('GB',  GradientBoostingClassifier(n_estimators=100, random_state=42)),\n",
        "], voting='soft')\n",
        "\n",
        "ens.fit(X_tr_sel, y_tr_res)\n",
        "yp_e  = ens.predict(X_te_sel)\n",
        "ypr_e = ens.predict_proba(X_te_sel)[:, 1]\n",
        "\n",
        "ea = accuracy_score(y_te, yp_e)\n",
        "ef = f1_score(y_te, yp_e)\n",
        "eu = roc_auc_score(y_te, ypr_e)\n",
        "\n",
        "print(f\"  Ensemble | Acc:{ea:.4f} | F1:{ef:.4f} | AUC:{eu:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_te, yp_e, target_names=['Not CKD', 'CKD']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C181iIF3zGR",
        "outputId": "90b348e2-223d-43cc-927d-642e2e7d4e06"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 9: SOFT VOTING ENSEMBLE (SVM + HistGB + GB)\n",
            "---------------------------------------------\n",
            "  Ensemble | Acc:0.9078 | F1:0.9471 | AUC:0.8705\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Not CKD       0.69      0.60      0.64        57\n",
            "         CKD       0.94      0.96      0.95       355\n",
            "\n",
            "    accuracy                           0.91       412\n",
            "   macro avg       0.82      0.78      0.79       412\n",
            "weighted avg       0.90      0.91      0.90       412\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 12. CONFUSION MATRICES\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "ax = axes.flatten()\n",
        "\n",
        "for i, (nm, clf) in enumerate(trained.items()):\n",
        "    yp = clf.predict(X_te_sel)\n",
        "    ConfusionMatrixDisplay(confusion_matrix(y_te, yp),\n",
        "                           display_labels=['Not CKD', 'CKD']).plot(\n",
        "        ax=ax[i], colorbar=False, cmap='Blues')\n",
        "    ax[i].set_title(f\"{nm}\\nAcc:{accuracy_score(y_te,yp):.4f}\", fontsize=9)\n",
        "\n",
        "ConfusionMatrixDisplay(confusion_matrix(y_te, yp_e),\n",
        "                       display_labels=['Not CKD', 'CKD']).plot(\n",
        "    ax=ax[7], colorbar=False, cmap='Greens')\n",
        "ax[7].set_title(f\"Soft Voting Ensemble\\nAcc:{ea:.4f}\", fontsize=9)\n",
        "\n",
        "plt.suptitle('Confusion Matrices â€” All Models', fontsize=15)\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrices.png', dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"ğŸ“Š Saved: confusion_matrices.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRfk-ghg4O13",
        "outputId": "9da05fb6-c50f-453e-dc2b-4db15daa340b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Saved: confusion_matrices.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 13. MODEL COMPARISON PLOT\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "all_r = te_df.copy()\n",
        "all_r.loc['Soft Voting Ensemble'] = [ea, ef, eu]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(13, 6))\n",
        "x = np.arange(len(all_r))\n",
        "w = 0.25\n",
        "ax.bar(x - w, all_r['Test Accuracy'], w, label='Accuracy',  color='#3498db')\n",
        "ax.bar(x,     all_r['Test F1'],       w, label='F1 Score',  color='#e67e22')\n",
        "ax.bar(x + w, all_r['Test AUC-ROC'],  w, label='AUC-ROC',   color='#27ae60')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(all_r.index, rotation=30, ha='right', fontsize=9)\n",
        "ax.set_ylim(0.8, 1.02)\n",
        "ax.set_ylabel('Score', fontsize=12)\n",
        "ax.set_title('Model Performance â€” Test Set', fontsize=14)\n",
        "ax.legend(); ax.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"ğŸ“Š Saved: model_comparison.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "appiO8bE4Y4v",
        "outputId": "13c5509a-af6b-4b13-f574-7c4ee0465e10"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Saved: model_comparison.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 14. SHAP EXPLAINABILITY\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"\\nSTEP 10: SHAP EXPLAINABILITY\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "explainer = shap.TreeExplainer(trained['Hist Gradient Boosting'])\n",
        "sv = explainer.shap_values(X_te_sel)\n",
        "\n",
        "if isinstance(sv, list):\n",
        "    sv = sv[1]\n",
        "elif hasattr(sv, 'ndim') and sv.ndim == 3:\n",
        "    sv = sv[:, :, 1]\n",
        "\n",
        "fl = list(consens)\n",
        "\n",
        "# Beeswarm\n",
        "plt.figure(figsize=(10, 6))\n",
        "shap.summary_plot(sv, X_te_sel, feature_names=fl, show=False, plot_type='dot')\n",
        "plt.title('SHAP Summary Plot â€” Hist Gradient Boosting (CKD)', fontsize=13)\n",
        "plt.tight_layout()\n",
        "plt.savefig('shap_summary.png', dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"ğŸ“Š Saved: shap_summary.png\")\n",
        "\n",
        "# Bar\n",
        "plt.figure(figsize=(9, 5))\n",
        "shap.summary_plot(sv, X_te_sel, feature_names=fl, show=False, plot_type='bar')\n",
        "plt.title('SHAP Feature Importance', fontsize=13)\n",
        "plt.tight_layout()\n",
        "plt.savefig('shap_bar.png', dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"ğŸ“Š Saved: shap_bar.png\")\n",
        "\n",
        "shap_imp = pd.DataFrame({\n",
        "    'Feature':     fl,\n",
        "    'Mean |SHAP|': np.abs(sv).mean(axis=0)\n",
        "}).sort_values('Mean |SHAP|', ascending=False)\n",
        "\n",
        "print(\"\\nTop Features by SHAP:\")\n",
        "print(shap_imp.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmTT1iwb3rR1",
        "outputId": "4cee0c1c-a55a-41eb-8bb4-d7611917ba3e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "STEP 10: SHAP EXPLAINABILITY\n",
            "---------------------------------------------\n",
            "ğŸ“Š Saved: shap_summary.png\n",
            "ğŸ“Š Saved: shap_bar.png\n",
            "\n",
            "Top Features by SHAP:\n",
            "Feature  Mean |SHAP|\n",
            "     sc     1.206513\n",
            "    pcv     1.179048\n",
            "     sg     0.837398\n",
            "    bgr     0.825889\n",
            "     bp     0.722170\n",
            "   rbcc     0.507404\n",
            "     dm     0.494335\n",
            "     al     0.411935\n",
            "    htn     0.399728\n",
            "  appet     0.119590\n",
            "     pe     0.029165\n",
            "     su     0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# FINAL SUMMARY\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"\\n\" + \"=\" * 65)\n",
        "print(\"  FINAL SUMMARY\")\n",
        "print(\"=\" * 65)\n",
        "print(\"\\nğŸ“‹ CV Results:\")\n",
        "print(cv_df.to_string())\n",
        "print(\"\\nğŸ“‹ Test Results:\")\n",
        "print(all_r.round(4).to_string())\n",
        "print(f\"\\nğŸ† Best Model    : {best_nm}\")\n",
        "print(f\"   Accuracy      : {best_ac:.4f} | 95% CI:[{ci_l:.3f},{ci_h:.3f}]\")\n",
        "\n",
        "print(f\"\\nğŸ† Ensemble (SVM + HistGB + GB)\")\n",
        "\n",
        "print(f\"   Acc:{ea:.4f} | F1:{ef:.4f} | AUC:{eu:.4f}\")\n",
        "print(f\"\\nğŸ”‘ Top-5 SHAP Features:\")\n",
        "for _, r in shap_imp.head(5).iterrows():\n",
        "    print(f\"   {r['Feature']:15s} â†’ {r['Mean |SHAP|']:.4f}\")\n",
        "\n",
        "print(\"\"\"\n",
        "âœ… Pipeline complete! Output files:\n",
        "   ğŸ“„ merged_ckd_dataset.csv\n",
        "   ğŸ“Š feature_selection_votes.png\n",
        "   ğŸ“Š confusion_matrices.png\n",
        "   ğŸ“Š model_comparison.png\n",
        "   ğŸ“Š shap_summary.png\n",
        "   ğŸ“Š shap_bar.png\n",
        "   ğŸ“„ cv_results.csv\n",
        "   ğŸ“„ test_results.csv\n",
        "   ğŸ“„ shap_importance.csv\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOUobAkf4zN6",
        "outputId": "f61c6f3e-3115-40db-b6d1-eef762e1a865"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=================================================================\n",
            "  FINAL SUMMARY\n",
            "=================================================================\n",
            "\n",
            "ğŸ“‹ CV Results:\n",
            "                        CV Accuracy   CV F1  CV AUC-ROC\n",
            "Decision Tree                0.8939  0.8930      0.8939\n",
            "Random Forest                0.9263  0.9272      0.9781\n",
            "Gradient Boosting            0.8989  0.9030      0.9646\n",
            "Hist Gradient Boosting       0.9179  0.9185      0.9742\n",
            "SVM                          0.8735  0.8823      0.9450\n",
            "KNN                          0.8862  0.8852      0.9591\n",
            "Logistic Regression          0.8111  0.8195      0.9002\n",
            "\n",
            "ğŸ“‹ Test Results:\n",
            "                        Test Accuracy  Test F1  Test AUC-ROC\n",
            "Decision Tree                  0.8762   0.9268        0.7883\n",
            "Random Forest                  0.8981   0.9412        0.8708\n",
            "Gradient Boosting              0.9078   0.9472        0.8759\n",
            "Hist Gradient Boosting         0.8859   0.9339        0.8585\n",
            "SVM                            0.9126   0.9497        0.8619\n",
            "KNN                            0.8519   0.9112        0.8079\n",
            "Logistic Regression            0.8374   0.9007        0.8782\n",
            "Soft Voting Ensemble           0.9078   0.9471        0.8705\n",
            "\n",
            "ğŸ† Best Model    : SVM\n",
            "   Accuracy      : 0.9126 | 95% CI:[0.881,0.936]\n",
            "\n",
            "ğŸ† Ensemble (SVM + HistGB + GB)\n",
            "   Acc:0.9078 | F1:0.9471 | AUC:0.8705\n",
            "\n",
            "ğŸ”‘ Top-5 SHAP Features:\n",
            "   sc              â†’ 1.2065\n",
            "   pcv             â†’ 1.1790\n",
            "   sg              â†’ 0.8374\n",
            "   bgr             â†’ 0.8259\n",
            "   bp              â†’ 0.7222\n",
            "\n",
            "âœ… Pipeline complete! Output files:\n",
            "   ğŸ“„ merged_ckd_dataset.csv\n",
            "   ğŸ“Š feature_selection_votes.png\n",
            "   ğŸ“Š confusion_matrices.png\n",
            "   ğŸ“Š model_comparison.png\n",
            "   ğŸ“Š shap_summary.png\n",
            "   ğŸ“Š shap_bar.png\n",
            "   ğŸ“„ cv_results.csv\n",
            "   ğŸ“„ test_results.csv\n",
            "   ğŸ“„ shap_importance.csv\n",
            "\n"
          ]
        }
      ]
    }
  ]
}